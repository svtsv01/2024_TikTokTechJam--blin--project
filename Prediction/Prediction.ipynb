{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel, BertTokenizerFast, AdamW, get_linear_schedule_with_warmup\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizerFast, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load data\n",
    "test_text = pd.read_csv('text_pred.tsv', sep='\\t', names=['text'])['text']\n",
    "#test_labels = pd.read_csv('test_labels.tsv', sep='\\t', names=['label'])['label']\n",
    "\n",
    "# test = pd.read_csv('./Data_L/test_l.csv')\n",
    "# test_text = test['text']\n",
    "# test_labels = test['label']\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Tokenize and encode sequences\n",
    "#print('tokenizing...')\n",
    "max_length = 128\n",
    "tokens_test = tokenizer.batch_encode_plus(test_text.tolist(), max_length=max_length, pad_to_max_length=True, truncation=True)\n",
    "#print('finished tokenizing')\n",
    "\n",
    "# Convert lists to tensors\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "#test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "# Model definition\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = BERT_Arch(bert)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load best model and evaluate on test data\n",
    "model.load_state_dict(torch.load('saved_weights.pt', map_location=torch.device('cpu')))\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "preds = np.argmax(preds, axis=1)\n",
    "print(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video\n",
      " https://www.tiktok.com/@textplot/video/7395979047253200160?_r=1 \n",
      "to\n",
      " c:\\Users\\pogiz\\OneDrive\\PC\\Projects\\2024_TikTokTechJam--blin--project\\Prediction\n",
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Transcription: would you like to show your faces first off you called me sir right now what's your name Erica oh wait one more time I didn't catch that see you soon those are kids you knew exactly what they were doing no they're not ignorant rocked in their hateful there's a difference hate is learnt they deserve for that video to be seen by the world I would imagine their parents are at the same mind if my kid was walking around harassing trans people on the street I want them to know it's not a light thing it's not like oh they're just being kids know an opportunity for them to learn sure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "would you like to show your faces first off you called me sir right now what's your name Erica oh wait one more time I didn't catch that see you soon those are kids you knew exactly what they were doing no they're not ignorant rocked in their hateful there's a difference hate is learnt they deserve for that video to be seen by the world I would imagine their parents are at the same mind if my kid was walking around harassing trans people on the street I want them to know it's not a light thing it's not like oh they're just being kids know an opportunity for them to learn sure\n"
     ]
    }
   ],
   "source": [
    "import pyktok as pyk\n",
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def extract_audio_from_video(video_path, audio_path):\n",
    "    video = mp.VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_path, codec='pcm_s16le')\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    # Load audio file with pydub\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    \n",
    "    # Export audio to wav format\n",
    "    wav_path = \"temp.wav\"\n",
    "    audio.export(wav_path, format=\"wav\")\n",
    "    \n",
    "    with sr.AudioFile(wav_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data, language='en-EN')\n",
    "        except sr.UnknownValueError:\n",
    "            print(0)\n",
    "        except sr.RequestError as e:\n",
    "            text = f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "\n",
    "    os.remove(wav_path)  # Clean up temporary file\n",
    "    return text\n",
    "\n",
    "def transcribe_video(video_path):\n",
    "    audio_path = \"temp_audio.wav\"\n",
    "    \n",
    "    try:\n",
    "        extract_audio_from_video(video_path, audio_path)\n",
    "        transcription = transcribe_audio(audio_path)\n",
    "        return transcription\n",
    "    finally:\n",
    "        if os.path.exists(audio_path):\n",
    "            os.remove(audio_path)  # Clean up temporary file\n",
    "\n",
    "tt_link = 'https://www.tiktok.com/@textplot/video/7395979047253200160?_r=1'\n",
    "\n",
    "pyk.specify_browser('chrome')\n",
    "pyk.save_tiktok(tt_link, True)\n",
    "\n",
    "for file in os.listdir('.'):\n",
    "    if fnmatch.fnmatch(file, '*@*'):\n",
    "        video_path = file\n",
    "\n",
    "video_path = \"test_2.mp4\"\n",
    "transcription = transcribe_video(video_path)\n",
    "print(\"Transcription:\", transcription)\n",
    "\n",
    "# Load data\n",
    "#test_text = pd.read_csv('text_pred.tsv', sep='\\t', names=['text'])['text']\n",
    "#test_labels = pd.read_csv('test_labels.tsv', sep='\\t', names=['label'])['label']\n",
    "test_text = [transcription]\n",
    "\n",
    "# test = pd.read_csv('./Data_L/test_l.csv')\n",
    "# test_text = test['text']\n",
    "# test_labels = test['label']\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Tokenize and encode sequences\n",
    "#print('tokenizing...')\n",
    "max_length = 128\n",
    "tokens_test = tokenizer.batch_encode_plus(test_text, max_length=max_length, pad_to_max_length=True, truncation=True)\n",
    "#print('finished tokenizing')\n",
    "\n",
    "# Convert lists to tensors\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "#test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "# Model definition\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = BERT_Arch(bert)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load best model and evaluate on test data\n",
    "model.load_state_dict(torch.load('../saved_weights.pt', map_location=torch.device('cpu')))\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "preds = np.argmax(preds, axis=1)\n",
    "print(preds[0])\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Video' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m tiktok_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.tiktok.com/@howridiculous/video/7395408759939435794\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownloaded_tiktok_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 25\u001b[0m download_tiktok_video(tiktok_url, output_path)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo downloaded and saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mdownload_tiktok_video\u001b[1;34m(tiktok_url, output_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m video_data \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mvideo(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mvideo_id)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get the download URL\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m download_url \u001b[38;5;241m=\u001b[39m video_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownloadAddr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Download the video\u001b[39;00m\n\u001b[0;32m     17\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(download_url)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Video' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from TikTokApi import TikTokApi\n",
    "import requests\n",
    "\n",
    "def download_tiktok_video(tiktok_url, output_path):\n",
    "    api = TikTokApi()\n",
    "    \n",
    "    # Extract the video ID from the TikTok URL\n",
    "    video_id = tiktok_url.split('/video/')[1].split('?')[0]\n",
    "    \n",
    "    # Get the video data\n",
    "    video_data = api.video(id=video_id)\n",
    "    \n",
    "    # Get the download URL\n",
    "    download_url = video_data['video']['downloadAddr']\n",
    "    \n",
    "    # Download the video\n",
    "    response = requests.get(download_url)\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Example usage\n",
    "tiktok_url = 'https://www.tiktok.com/@howridiculous/video/7395408759939435794'\n",
    "output_path = 'downloaded_tiktok_video.mp4'\n",
    "download_tiktok_video(tiktok_url, output_path)\n",
    "\n",
    "print(f\"Video downloaded and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
